# LLM Embedded for Robots in ROS2 ü§ñü¶æ

[![ROS2 Humble](https://img.shields.io/badge/ROS2-Humble-blue.svg)](https://docs.ros.org/en/humble/)
[![Python](https://img.shields.io/badge/Python-3.10+-yellow.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)


**LLM-Embedded-for-Robots-in-ROS2** is a ROS2 framework that fuses a local Large Language Model with a full offline speech pipeline so robots can understand and respond to natural language without the cloud.

---

## üìö Table of Contents
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Usage](#usage)
- [Configuration](#configuration)
- [Contributing](#contributing) 
- [License](#license)
- [Acknowledgements](#acknowledgements)

---

## üõ†Ô∏è Installation
> [!IMPORTANT]
> Ensure ROS2 Humble and Python ‚â•3.10 are installed before continuing.

### Prerequisites
- Ubuntu 22.04
- [ROS2 Humble](https://docs.ros.org/en/humble/Installation.html)
- Python 3.10.12 
- Git, CMake, colcon
- (Optional) NVIDIA CUDA for GPU acceleration
- (Suggestion) Use Virtual Enfoment


### Setup
```bash
$ sudo dnf install portaudio-devel python3-devel
```

```bash
# Clone the repository
$ git clone https://github.com/JossueE/LLM-Embedded-for-Robots-in-ROS2.git
$ cd LLM-Embedded-for-Robots-in-ROS2
```
```bash
# Create a virtual environment
$ python3 -m venv .venv
$ source .venv/bin/activate
$ python -m pip install -U pip
```
```bash
# Install dependencies
(.venv) $ pip install -r requirements.txt
```
```bash
# Build ROS2 packages
(.venv) $ colcon build
(.venv) $ source install/setup.bash
```
---

## ‚ö° Quick Start
Run the example launch file to start the wake-word ‚Üí STT ‚Üí LLM ‚Üí TTS pipeline:
```bash
(.venv) $ ros2 launch LLM LLM.launch.py
```
The fisrt time, the models will be donwloaded, so it could take a little bit. Don't say anithing until you see.
```bash
[llm_main-4] [INFO] [xxxxxxxxxx.xxxxxxxxx] [octopy_agent]: Octopy listo ‚úÖ  Publica en /transcript
```
and
```bash
[stt-3] [INFO] [xxxxxxxxxx.xxxxxxxxxx] [silero_stt_node]: Silero listo üîä SR=16000ch=1 device=cpu lang=es
[stt-3] Transcribe cuando /flag_wake_word cae de True a False.

[tts-6] [INFO] [1756768229.614419483] [silero_tts_node]: Silero TTS listo üîä rate=24000 device=cpu lang=es speaker=v3_es
```

### Test just a Node
You could use the follow example or try to speak in the microphone
```bash
# Run the LLM agent Node
$ home/<your user>/LLM-Embedded-for-Robots-in-ROS2/.venv/bin/python3 /home/<your user>/LLM-Embedded-for-Robots-in-ROS2/install/LLM/lib/LLM/llm_main
```
> [!TIP]
> By this way you are sure that you call your virtual env

Mic ‚Üí Wake Word ‚Üí STT ‚Üí LLM/Tools ‚Üí TTS ‚Üí Speaker
```

## üìÇ Project Structure
```text
LLM-Embedded-for-Robots-in-ROS2/
‚îú‚îÄ‚îÄ src/
|   ‚îú‚îÄ‚îÄconfig
|   |  ‚îú‚îÄ‚îÄkb.json
|   |  ‚îî‚îÄ‚îÄ poses.json
‚îÇ   ‚îî‚îÄ‚îÄ LLM/                 # ROS2 package: agent, STT, wake word, TTS
‚îÇ       ‚îú‚îÄ‚îÄllm_utils
‚îÇ       ‚îÇ  ‚îú‚îÄ‚îÄllm_client.py 
‚îÇ       ‚îÇ  ‚îú‚îÄ‚îÄllm_intentions.py 
‚îÇ       ‚îÇ  ‚îú‚îÄ‚îÄllm_router.py 
‚îÇ       ‚îÇ  ‚îî‚îÄ‚îÄllm_tools.py 
‚îÇ       ‚îú‚îÄ‚îÄaudio_listener.py 
‚îÇ       ‚îú‚îÄ‚îÄllm_main.py 
‚îÇ       ‚îú‚îÄ‚îÄspeech_to_text.py 
‚îÇ       ‚îî‚îÄ‚îÄwake_word_detector
‚îú‚îÄ‚îÄ models.yml               # Auto-downloaded model list
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```
## üß™ Usage
### ROS Topics
- `/audio` ‚Äì raw audio input
- `/flag_wake_word` ‚Äì wake word detection flag
- `/transcript` ‚Äì speech-to-text output
- `/octopy/ask` ‚Äì text questions to the LLM agent
- `/octopy/answer` ‚Äì agent replies
- `/battery_state` ‚Äì battery feedback for tools
- `/amcl_pose` ‚Äì pose feedback for tools

## ‚öôÔ∏è Configuration
> [!WARNING]
> Large models require significant disk space; check `models.yml` for sizes.

### Performance
```bash
# Limit CPU threads used by llama.cpp
$ export OCTOPY_THREADS=4
```
Other optional variables: `OCTOPY_CTX`, `OCTOPY_N_BATCH`, `OCTOPY_N_GPU_LAYERS`.

## ü§ù Contributing
Contributions are welcome! Please fork the repository and submit a pull request. For major changes, open an issue first to discuss what you would like to change.

---

## üìÑ License   
This project is licensed under the [MIT License](LICENSE).

---

## üôè Acknowledgements
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [Vosk](https://alphacephei.com/vosk/)
- [Silero Models](https://github.com/snakers4/silero-models)
- [Qwen Models](https://huggingface.co/Qwen)
- The ROS2 community